{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "from tensorflow_probability import distributions as dists\n",
    "import tensorflow.keras.layers as kl\n",
    "import datetime\n",
    "\n",
    "from rl_agents.env_utils import rollouts_generator, get_adv_vtarg\n",
    "from rl_agents.ppo.policy import Actor, Critic\n",
    "from rl_agents.ppo.agent import PPO_Agent\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard.notebook\n",
    "\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GYM environment\n",
    "Use Pendulum-v0 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0805 15:39:25.075204 4562228672 registration.py:117] Making new env: Pendulum-v0\n",
      "[2019-08-05 15:39:25,075] Making new env: Pendulum-v0\n",
      "/Users/raiszo/neu_env/.venv/lib/python3.6/site-packages/gym/envs/registration.py:17: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "is_continuous = isinstance(env.action_space, gym.spaces.Box)\n",
    "obs_dim = env.observation_space.shape\n",
    "act_dim = env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor(obs_dim, act_dim, is_continuous)\n",
    "critic = Critic(obs_dim)\n",
    "vero = PPO_Agent(actor, critic)\n",
    "generator = rollouts_generator(vero, env, horizon=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ite = 200\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "num_epochs = 10\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_ite):\n",
    "    rollout = generator.__next__()\n",
    "    advantage, target_value = get_adv_vtarg(rollout, lam=lam, gamma=gamma)\n",
    "    vero.run_ite(rollout['ob'], rollout['ac'], rollout['log_probs'], target_value, advantage,\n",
    "                 epochs=num_epochs)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('reward mean', np.array(rollout[\"ep_rets\"]).mean(), step=i*num_epochs)\n",
    "    \n",
    "    if i % 50 == 0 or i == num_ite-1:\n",
    "        actor.save_weights(train_log_dir+'/_actor_'+str(i), save_format='tf')\n",
    "        critic.save_weights(train_log_dir+'/_critic_'+str(i), save_format='tf')\n",
    "    #    mean, std = rewards.mean(), rewards.std()\n",
    "    #    print('mean', mean)\n",
    "    #    print('std', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'std:0' shape=(1, 1) dtype=float64, numpy=array([[0.58860497]])>\n",
      "0 0\n",
      "new Tensor(\"Mean:0\", shape=(), dtype=float64)\n",
      "old Tensor(\"Mean_1:0\", shape=(), dtype=float64)\n",
      "new Tensor(\"Mean:0\", shape=(), dtype=float64)\n",
      "old Tensor(\"Mean_1:0\", shape=(), dtype=float64)\n",
      "diff: -4.0766001685454967e-17\n",
      "0 1\n",
      "diff: -0.0004211451810702772\n",
      "0 2\n",
      "diff: 0.00081224113848570988\n",
      "1 0\n",
      "diff: -0.0063206756430890113\n",
      "1 1\n",
      "diff: -0.0026559922109236425\n",
      "1 2\n",
      "diff: 0.00014958576504965366\n",
      "<tf.Variable 'std:0' shape=(1, 1) dtype=float64, numpy=array([[0.58864946]])>\n",
      "0 0\n",
      "diff: -8.05096362967335e-05\n",
      "0 1\n",
      "diff: 0.00017542572215368396\n",
      "0 2\n",
      "diff: -0.00030279099071196542\n",
      "1 0\n",
      "diff: -0.00012270078524950333\n",
      "1 1\n",
      "diff: 0.00027628637488492404\n",
      "1 2\n",
      "diff: -0.00083996432288247023\n"
     ]
    }
   ],
   "source": [
    "actor2 = Actor(obs_dim, act_dim, is_continuous)\n",
    "critic2 = Critic(obs_dim)\n",
    "vero2 = PPO_Agent(actor2, critic2)\n",
    "generator2 = rollouts_generator(vero2, env, horizon=2048)\n",
    "\n",
    "num_ite = 2\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "num_epochs = 2\n",
    "\n",
    "for i in range(num_ite):\n",
    "    rollout = generator2.__next__()\n",
    "    advantage, target_value = get_adv_vtarg(rollout, lam=lam, gamma=gamma)\n",
    "    vero2.run_ite(rollout['ob'], rollout['ac'], rollout['log_probs'], target_value, advantage,\n",
    "                  epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "ac, v, lp = vero.act_stochastic(obs)\n",
    "print(lp)\n",
    "l = vero.get_distributions(obs[None])\n",
    "print(l.log_prob(ac))\n",
    "print(l.entropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = env.action_space.sample()\n",
    "print(ac.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = tfd.Normal(loc=np.array([0., 1, 2, 0.5]), scale=np.array([0.02, 0.09, 0.1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = rollouts_generator(vero, env, horizon=2048)\n",
    "\n",
    "rollout = generator.__next__()\n",
    "advantage, target_value = get_adv_vtarg(rollout, lam=0.95, gamma=0.99)\n",
    "vero.run_epoch(rollout['ob'], rollout['ac'], rollout['log_probs'], target_value, advantage, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'std:0' shape=(1, 1) dtype=float64, numpy=array([[0.59058199]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor2.trainable_variables[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-0.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "from tensorflow_probability import distributions as dists\n",
    "import tensorflow.keras.layers as kl\n",
    "import datetime\n",
    "import scipy.signal\n",
    "\n",
    "from rl_agents.env_utils import rollouts_generator, get_adv_vtarg, get_gaeadv_vtarg\n",
    "from rl_agents.vpg.agent import VPG_Agent\n",
    "from rl_agents.ppo.agent import PPO_Agent\n",
    "from rl_agents.policies.categorical import CategoricalActor\n",
    "from rl_agents.policies.gaussian import GaussianActor\n",
    "from rl_agents.common import Critic\n",
    "from rl_agents.trainer.sensei import Sensei\n",
    "\n",
    "from gym.spaces import Box, Discrete\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GYM environment\n",
    "Use Pendulum-v0 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_fn = lambda: gym.make('MountainCarContinuous-v0')\n",
    "# env_fn = lambda: gym.make('Pendulum-v0')\n",
    "# env_fn = lambda: gym.make('MountainCar-v0')\n",
    "env_fn = lambda: gym.make('CartPole-v0')\n",
    "env = env_fn()\n",
    "is_continuous = isinstance(env.action_space, gym.spaces.Box)\n",
    "obs_dim = env.observation_space.shape\n",
    "act_dim = env.action_space.shape if is_continuous else env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_ppo = GaussianActor(obs_dim, act_dim) if is_continuous else CategoricalActor(obs_dim, act_dim)\n",
    "critic_ppo = Critic(obs_dim)\n",
    "jen_ppo = PPO_Agent(actor_ppo, critic_ppo, is_continuous, act_dim)\n",
    "generator_ppo = rollouts_generator(jen_ppo, env, is_continuous, horizon=2048)\n",
    "\n",
    "alg_name = \"PPO\"\n",
    "num_ite = 200\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "epochs_actor = 20\n",
    "epochs_critic = 40\n",
    "sensei_ppo = Sensei(jen_ppo, alg_name, env_fn,\n",
    "                    ite=num_ite, horizon=2048,\n",
    "                    epochs_actor=epochs_actor, epochs_critic=epochs_critic,\n",
    "                    gamma=gamma, gae_lambda=lam,\n",
    "                    log_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensei_ppo.train(batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Policy Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_vpg = GaussianActor(obs_dim, act_dim) if is_continuous else CategoricalActor(obs_dim, act_dim)\n",
    "critic_vpg = Critic(obs_dim)\n",
    "jen_vpg = VPG_Agent(actor_vpg, critic_vpg, is_continuous, act_dim)\n",
    "generator_vpg = rollouts_generator(jen_vpg, env, is_continuous, horizon=2048)\n",
    "\n",
    "alg_name = \"VPG\"\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "epochs_actor = 1\n",
    "epochs_critic = 40\n",
    "sensei_vpg = Sensei(jen_vpg, alg_name, env_fn,\n",
    "                    horizon=2048, epochs_actor=epochs_actor, epochs_critic=epochs_critic,\n",
    "                    gamma=gamma, gae_lambda=lam,\n",
    "                    log_dir='logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/f/Awesome/linux-env-dev/.venv/lib/python3.6/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "num_ite = 200\n",
    "sensei_vpg.train(num_ite, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_ite = 1\n",
    "sensei_vpg.train(num_ite, record=False, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_cumsum(x, discount):\n",
    "    \"\"\"\n",
    "    magic from rllab for computing discounted cumulative sums of vectors.\n",
    "    input: \n",
    "        vector x, \n",
    "        [x0, \n",
    "         x1, \n",
    "         x2]\n",
    "    output:\n",
    "        [x0 + discount * x1 + discount^2 * x2,  \n",
    "         x1 + discount * x2,\n",
    "         x2]\n",
    "    \"\"\"\n",
    "    return scipy.signal.lfilter([1], [1, float(-discount)], x[::-1], axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = generator_ppo.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gae, td = get_gaeadv_vtarg(rollout, 0.95, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rews, vals = rollout[\"rew\"][:198], rollout[\"vpred\"][:198]\n",
    "rews = np.append(rews, rollout[\"vpred\"])\n",
    "vals = np.append(vals, rollout[\"next_vpred\"])\n",
    "deltas = rews[:-1] + 0.99 * vals[1:] - vals[:-1]\n",
    "gae2 = discount_cumsum(deltas, 0.99*0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(gae2 - gae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gae2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gae-gae2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout[\"new\"][:198]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard.notebook extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard.notebook\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "from tensorflow_probability import distributions as dists\n",
    "import tensorflow.keras.layers as kl\n",
    "import datetime\n",
    "\n",
    "from rl_agents.env_utils import rollouts_generator, get_adv_vtarg\n",
    "from rl_agents.ppo.policy import Actor, Critic\n",
    "from rl_agents.ppo.agent import PPO_Agent\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard.notebook\n",
    "\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GYM environment\n",
    "Use Pendulum-v0 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 10:58:06.483407 4640867776 registration.py:117] Making new env: Pendulum-v0\n",
      "[2019-08-15 10:58:06,483] Making new env: Pendulum-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "is_continuous = isinstance(env.action_space, gym.spaces.Box)\n",
    "obs_dim = env.observation_space.shape\n",
    "act_dim = env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor(obs_dim, act_dim, is_continuous)\n",
    "critic = Critic(obs_dim)\n",
    "jen = PPO_Agent(actor, critic)\n",
    "generator = rollouts_generator(vero, env, horizon=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ite = 200\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "num_epochs = 10\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_ite):\n",
    "    rollout = generator.__next__()\n",
    "    advantage, target_value = get_adv_vtarg(rollout, lam=lam, gamma=gamma)\n",
    "    jen.run_ite(rollout['ob'], rollout['ac'], rollout['log_probs'], rollout['locs'], target_value, advantage,\n",
    "                 epochs=num_epochs)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('reward mean', np.array(rollout[\"ep_rets\"]).mean(), step=i*num_epochs)\n",
    "    \n",
    "    if i % 50 == 0 or i == num_ite-1:\n",
    "        actor.save_weights(train_log_dir+'/_actor_'+str(i), save_format='tf')\n",
    "        critic.save_weights(train_log_dir+'/_critic_'+str(i), save_format='tf')\n",
    "    #    mean, std = rewards.mean(), rewards.std()\n",
    "    #    print('mean', mean)\n",
    "    #    print('std', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10ea29a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### iteration ### 0\n",
      "#### iteration ### 1\n",
      "#### iteration ### 2\n"
     ]
    }
   ],
   "source": [
    "actor2 = Actor(obs_dim, act_dim, is_continuous)\n",
    "critic2 = Critic(obs_dim)\n",
    "vero2 = PPO_Agent(actor2, critic2)\n",
    "generator2 = rollouts_generator(vero2, env, horizon=2048)\n",
    "\n",
    "num_ite = 200\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "num_epochs = 10\n",
    "\n",
    "for i in range(num_ite):\n",
    "    print('#### iteration ###', i)\n",
    "    rollout = generator2.__next__()\n",
    "    # print(rollout['ac'][0:10])\n",
    "    advantage, target_value = get_adv_vtarg(rollout, lam=lam, gamma=gamma)\n",
    "    vero2.run_ite(rollout['ob'], rollout['ac'], rollout['log_probs'], rollout['locs'], target_value, advantage,\n",
    "                  epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor3 = Actor(obs_dim, act_dim, is_continuous)\n",
    "critic3 = Critic(obs_dim)\n",
    "vero3 = PPO_Agent(actor3, critic3)\n",
    "\n",
    "num_ite = 3\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "\n",
    "for i in range(num_ite):\n",
    "    print('#### iteration ###', i)\n",
    "    \n",
    "    rollout = generator2.__next__()\n",
    "    # print(rollout['ac'][0:10])\n",
    "    advantage, target_value = get_adv_vtarg(rollout, lam=lam, gamma=gamma)\n",
    "    vero2.run_ite(rollout['ob'], rollout['ac'], rollout['log_probs'], target_value, advantage,\n",
    "                  epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "ac, v, lp = vero.act_stochastic(obs)\n",
    "print(lp)\n",
    "l = vero.get_distributions(obs[None])\n",
    "print(l.log_prob(ac))\n",
    "print(l.entropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = env.action_space.sample()\n",
    "print(ac.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = tfd.Normal(loc=np.array([0., 1, 2, 0.5]), scale=np.array([0.02, 0.09, 0.1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = rollouts_generator(vero, env, horizon=2048)\n",
    "\n",
    "rollout = generator.__next__()\n",
    "advantage, target_value = get_adv_vtarg(rollout, lam=0.95, gamma=0.99)\n",
    "vero.run_epoch(rollout['ob'], rollout['ac'], rollout['log_probs'], target_value, advantage, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'std:0' shape=(1, 1) dtype=float64, numpy=array([[0.59058199]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor2.trainable_variables[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-0.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

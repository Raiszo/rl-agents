{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard.notebook extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard.notebook\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "from tensorflow_probability import distributions as dists\n",
    "import tensorflow.keras.layers as kl\n",
    "import datetime\n",
    "\n",
    "from rl_agents.env_utils import rollouts_generator, get_adv_vtarg\n",
    "from rl_agents.vpg.agent import VPG_Agent\n",
    "from rl_agents.ppo.agent import PPO_Agent\n",
    "from rl_agents.policies.categorical import CategoricalActor\n",
    "from rl_agents.policies.gaussian import GaussianActor\n",
    "from rl_agents.common import Critic\n",
    "\n",
    "from gym.spaces import Box, Discrete\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard.notebook\n",
    "\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GYM environment\n",
    "Use Pendulum-v0 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('CartPole-v0')\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "is_continuous = isinstance(env.action_space, gym.spaces.Box)\n",
    "obs_dim = env.observation_space.shape\n",
    "act_dim = env.action_space.shape if is_continuous else env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Policy Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_vpg = GaussianActor(obs_dim, act_dim) if is_continuous else CategoricalActor(obs_dim, act_dim)\n",
    "critic_vpg = Critic(obs_dim)\n",
    "jen_vpg = VPG_Agent(actor_vpg, critic_vpg, is_continuous, act_dim)\n",
    "generator_vpg = rollouts_generator(jen_vpg, env, is_continuous, horizon=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"VPG\"\n",
    "num_ite = 200\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/{}_{}/'.format(env.unwrapped.spec.id, alg_name) + current_time\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "for i in range(num_ite):\n",
    "    rollout = generator_vpg.__next__()\n",
    "    adv, target_value = get_adv_vtarg(rollout, lam=lam, gamma=gamma)\n",
    "    adv = (adv - adv.mean()) / (adv.std() + 1e-8)\n",
    "    \n",
    "    jen_vpg.run_ite(rollout['ob'], rollout['ac'], rollout['log_probs'], target_value, adv, batch_size=512)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('reward mean', np.array(rollout[\"ep_rets\"]).mean(), step=i)\n",
    "    \n",
    "    if i % 50 == 0 or i == num_ite-1:\n",
    "        actor_vpg.save_weights(train_log_dir+'/_actor_'+str(i), save_format='tf')\n",
    "        critic_vpg.save_weights(train_log_dir+'/_critic_'+str(i), save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_ppo = GaussianActor(obs_dim, act_dim) if is_continuous else CategoricalActor(obs_dim, act_dim)\n",
    "critic_ppo = Critic(obs_dim)\n",
    "jen_ppo = PPO_Agent(actor_ppo, critic_ppo, is_continuous, act_dim)\n",
    "generator_ppo = rollouts_generator(jen_ppo, env, is_continuous, horizon=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"PPO\"\n",
    "num_ite = 200\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "epochs = 10\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/{}_{}/'.format(env.unwrapped.spec.id, alg_name) + current_time\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "for i in range(num_ite):\n",
    "    rollout = generator_ppo.__next__()\n",
    "    adv, target_value = get_adv_vtarg(rollout, lam=lam, gamma=gamma)\n",
    "    adv = (adv - adv.mean()) / (adv.std() + 1e-8)\n",
    "    \n",
    "    jen_ppo.run_ite(rollout['ob'], rollout['ac'], rollout['log_probs'], target_value, adv, epochs=epochs, batch_size=256)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('reward mean', np.array(rollout[\"ep_rets\"]).mean(), step=i)\n",
    "    \n",
    "    if i % 50 == 0 or i == num_ite-1:\n",
    "        actor_ppo.save_weights(train_log_dir+'/_actor_'+str(i), save_format='tf')\n",
    "        critic_ppo.save_weights(train_log_dir+'/_critic_'+str(i), save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/gradient_tape --port=8003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "actor2 = Actor(obs_dim, act_dim, is_continuous)\n",
    "critic2 = Critic(obs_dim)\n",
    "vero2 = PPO_Agent(actor2, critic2)\n",
    "generator2 = rollouts_generator(vero2, env, horizon=2048)\n",
    "\n",
    "num_ite = 200\n",
    "lam = 0.95\n",
    "gamma = 0.99\n",
    "num_epochs = 10\n",
    "\n",
    "for i in range(num_ite):\n",
    "    print('#### iteration ###', i)\n",
    "    rollout = generator2.__next__()\n",
    "    # print(rollout['ac'][0:10])\n",
    "    advantage, target_value = get_adv_vtarg(rollout, lam=lam, gamma=gamma)\n",
    "    vero2.run_ite(rollout['ob'], rollout['ac'], rollout['log_probs'], rollout['locs'], target_value, advantage,\n",
    "                  epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = rollouts_generator(jen, env, horizon=210)\n",
    "\n",
    "roll = generator.__next__()\n",
    "\n",
    "adv, tar = get_adv_vtarg(roll, lam=0.95, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll['rew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.88714555],\n",
       "       [-0.97320608],\n",
       "       [-1.08957951],\n",
       "       ...,\n",
       "       [-0.95047626],\n",
       "       [-1.2021399 ],\n",
       "       [-0.94937365]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollout['log_probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.spec.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jen_vpg.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

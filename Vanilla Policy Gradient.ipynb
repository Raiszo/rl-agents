{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tensorflow_probability import distributions as tfpd, layers as tfpl\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSample(kl.Layer):\n",
    "    def __init__(self, act_dim):\n",
    "        super(GaussianSample, self).__init__()\n",
    "        self.log_std = self.add_weight(\n",
    "            'log_std', initializer=tf.keras.initializers.Constant(-0.53), \n",
    "            shape=(act_dim,), trainable=True\n",
    "        )\n",
    "        self.normal_dist = tfpl.DistributionLambda(\n",
    "            make_distribution_fn=lambda t: tfpd.Normal(loc=t, scale=tf.exp(self.log_std)),\n",
    "            convert_to_tensor_fn=lambda s: s.sample(),\n",
    "        )\n",
    "    \n",
    "    #def build(self, input_shape):\n",
    "    #    \"\"\"\n",
    "    #    input_shape: might be [None, act_dim]\n",
    "    #    \"\"\"\n",
    "    #    self.log_std = self.add_weight(\n",
    "    #        'log_std', initializer=tf.keras.initializers.Constant(-0.53), \n",
    "    #        shape=(input_shape[1],), dtype='float32', trainable=True\n",
    "    #    )\n",
    "\n",
    "    def call(self, input):\n",
    "        #return tfpd.Normal(loc=input, scale=tf.exp(self.log_std))\n",
    "        return self.normal_dist(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(obs_dim: int, act_dim: int):\n",
    "    obs = keras.Input(shape=(obs_dim,), name='observations')\n",
    "    x = kl.Dense(32, activation='tanh', name='dense_1')(obs)\n",
    "    x = kl.Dense(act_dim, name='logits')(x)\n",
    "\n",
    "    pi = GaussianSample(act_dim)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=obs,\n",
    "                        outputs=[pi, x])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (distribution_lambda_4411), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'log_std:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    }
   ],
   "source": [
    "test_model = get_actor(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[-0.58579165]\n"
     ]
    }
   ],
   "source": [
    "obs = np.array([[ 0.69950885,  0.6432279 , -7.588761  ]])\n",
    "res = test_model(obs)\n",
    "print(res[0].sample()[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt_fn(model, lr=3e-4):\n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "    \n",
    "    #@tf.function\n",
    "    def step_fn(obs_no, act_na, adv_n):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logp = tf.reduce_sum(\n",
    "                model(obs_no)[0].log_prob(act_na),\n",
    "                axis=1,\n",
    "            )\n",
    "            \n",
    "            loss = tf.reduce_mean(-logp * adv_n)\n",
    "        \n",
    "        grad = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(grad, model.trainable_variables))\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    return opt, step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_to_go(rews):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + (rtgs[i+1] if i+1 < n else 0)\n",
    "    return rtgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, epochs=200, buffer_size=4096):\n",
    "    assert isinstance(env.observation_space, gym.spaces.Box), \\\n",
    "        \"This is only for continuous observation space\"\n",
    "    assert isinstance(env.action_space, gym.spaces.Box), \\\n",
    "        \"This is only for continuous action space\"\n",
    "    \n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    \n",
    "    model = get_actor(obs_dim, act_dim)\n",
    "    model.summary()\n",
    "    # keras.utils.plot_model(model, 'multi_output_model.png')\n",
    "    \n",
    "    \n",
    "    opt, step_fn = get_opt_fn(model)\n",
    "    \n",
    "    def train_one_epoch():\n",
    "        # make some empty lists for logging.\n",
    "        batch_obs = []          # for observations\n",
    "        batch_acts = []         # for actions\n",
    "        batch_weights = []      # for reward-to-go weighting in policy gradient\n",
    "        batch_rets = []         # for measuring episode returns\n",
    "        batch_lens = []         # for measuring episode lengths\n",
    "\n",
    "        # reset episode-specific variables\n",
    "        obs = env.reset()       # first obs comes from starting distribution\n",
    "        done = False            # signal from environment that episode is over\n",
    "        ep_rews = []            # list for rewards accrued throughout ep\n",
    "\n",
    "        # collect experience by acting in the environment with current policy\n",
    "        while True:\n",
    "            # save obs\n",
    "            batch_obs.append(obs.copy())\n",
    "\n",
    "            # act in the environment\n",
    "            act = model(obs[None])[0].sample()[0]\n",
    "            obs, rew, done, _ = env.step(act)\n",
    "\n",
    "            # save action, reward\n",
    "            batch_acts.append(act)\n",
    "            ep_rews.append(rew)\n",
    "\n",
    "            if done:\n",
    "                # if episode is over, record info about episode\n",
    "                ep_ret, ep_len = sum(ep_rews), len(ep_rews)\n",
    "                batch_rets.append(ep_ret)\n",
    "                batch_lens.append(ep_len)\n",
    "\n",
    "                # the weight for each logprob(a_t|s_t) is reward-to-go from t\n",
    "                batch_weights += list(reward_to_go(ep_rews))\n",
    "\n",
    "                # reset episode-specific variables\n",
    "                obs, done, ep_rews = env.reset(), False, []\n",
    "\n",
    "                # end experience loop if we have enough of it\n",
    "                if len(batch_obs) > buffer_size:\n",
    "                    break\n",
    "\n",
    "        # take a single policy gradient update step\n",
    "        batch_loss = step_fn(np.array(batch_obs), np.array(batch_acts), np.array(batch_weights))\n",
    "        return batch_rets, batch_lens, batch_loss\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        batch_rets, batch_lens, batch_loss = train_one_epoch()\n",
    "        if epochs % 50 == 0 or i == epochs-1:\n",
    "            model.save_weights('ckpts/_model_'+str(i), save_format='tf')\n",
    "        \n",
    "        print('epoch: %3d \\t loss: %.3f \\t return: %.3f \\t ep_len: %.3f'%\n",
    "              (i, batch_loss, np.mean(batch_rets), np.mean(batch_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (distribution_lambda_4418), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'log_std:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "observations (InputLayer)    [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "gaussian_sample_20 (Gaussian (None, 1)                 1         \n",
      "=================================================================\n",
      "Total params: 162\n",
      "Trainable params: 162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Layer dense_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   0 \t loss: -537.512 \t return: -1211.591 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   1 \t loss: -556.069 \t return: -1252.926 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   2 \t loss: -547.924 \t return: -1224.300 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   3 \t loss: -553.253 \t return: -1229.715 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   4 \t loss: -540.310 \t return: -1212.960 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   5 \t loss: -540.599 \t return: -1242.601 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   6 \t loss: -560.476 \t return: -1239.550 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   7 \t loss: -545.166 \t return: -1228.388 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   8 \t loss: -561.620 \t return: -1259.074 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:   9 \t loss: -538.078 \t return: -1216.409 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  10 \t loss: -539.865 \t return: -1222.025 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  11 \t loss: -539.319 \t return: -1218.274 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  12 \t loss: -564.615 \t return: -1229.226 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  13 \t loss: -558.608 \t return: -1240.886 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  14 \t loss: -557.514 \t return: -1253.899 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  15 \t loss: -534.037 \t return: -1196.401 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  16 \t loss: -530.283 \t return: -1222.107 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  17 \t loss: -561.328 \t return: -1234.178 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  18 \t loss: -552.092 \t return: -1229.131 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  19 \t loss: -543.276 \t return: -1214.884 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  20 \t loss: -545.923 \t return: -1219.178 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  21 \t loss: -554.300 \t return: -1218.714 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  22 \t loss: -554.282 \t return: -1238.727 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  23 \t loss: -564.802 \t return: -1267.718 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  24 \t loss: -546.165 \t return: -1241.265 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  25 \t loss: -530.429 \t return: -1246.190 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  26 \t loss: -556.980 \t return: -1228.046 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  27 \t loss: -552.306 \t return: -1232.394 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  28 \t loss: -544.307 \t return: -1237.575 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  29 \t loss: -550.346 \t return: -1200.070 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  30 \t loss: -531.154 \t return: -1216.284 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  31 \t loss: -558.794 \t return: -1250.497 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  32 \t loss: -557.053 \t return: -1207.261 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  33 \t loss: -555.903 \t return: -1237.134 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  34 \t loss: -554.868 \t return: -1231.582 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  35 \t loss: -541.612 \t return: -1220.249 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  36 \t loss: -533.568 \t return: -1251.683 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  37 \t loss: -547.189 \t return: -1230.291 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  38 \t loss: -539.758 \t return: -1217.128 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  39 \t loss: -536.135 \t return: -1224.915 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  40 \t loss: -539.794 \t return: -1191.722 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  41 \t loss: -546.906 \t return: -1260.077 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  42 \t loss: -545.117 \t return: -1205.615 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  43 \t loss: -548.725 \t return: -1214.437 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  44 \t loss: -550.862 \t return: -1222.380 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  45 \t loss: -533.576 \t return: -1175.966 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  46 \t loss: -533.292 \t return: -1199.354 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  47 \t loss: -536.866 \t return: -1217.101 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  48 \t loss: -534.677 \t return: -1216.492 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  49 \t loss: -536.659 \t return: -1211.049 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  50 \t loss: -548.033 \t return: -1213.055 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  51 \t loss: -551.882 \t return: -1207.685 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  52 \t loss: -546.291 \t return: -1215.721 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  53 \t loss: -528.863 \t return: -1201.907 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  54 \t loss: -539.522 \t return: -1207.927 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  55 \t loss: -530.488 \t return: -1237.186 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  56 \t loss: -556.002 \t return: -1191.524 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  57 \t loss: -545.977 \t return: -1192.970 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  58 \t loss: -517.954 \t return: -1219.145 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  59 \t loss: -543.451 \t return: -1214.933 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  60 \t loss: -549.367 \t return: -1224.828 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  61 \t loss: -540.324 \t return: -1185.394 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_na (4200, 1)\n",
      "epoch:  62 \t loss: -540.857 \t return: -1193.905 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  63 \t loss: -530.464 \t return: -1190.973 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  64 \t loss: -526.222 \t return: -1218.800 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  65 \t loss: -546.300 \t return: -1246.581 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  66 \t loss: -538.859 \t return: -1223.026 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  67 \t loss: -547.730 \t return: -1229.270 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  68 \t loss: -541.904 \t return: -1194.556 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  69 \t loss: -536.896 \t return: -1192.802 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  70 \t loss: -543.042 \t return: -1182.757 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  71 \t loss: -559.028 \t return: -1219.978 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  72 \t loss: -542.652 \t return: -1200.395 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  73 \t loss: -540.388 \t return: -1208.830 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  74 \t loss: -538.496 \t return: -1219.762 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  75 \t loss: -550.447 \t return: -1240.471 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  76 \t loss: -537.923 \t return: -1212.297 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  77 \t loss: -548.030 \t return: -1231.801 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  78 \t loss: -545.705 \t return: -1205.704 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  79 \t loss: -551.187 \t return: -1206.268 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  80 \t loss: -558.251 \t return: -1271.577 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  81 \t loss: -566.014 \t return: -1282.660 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  82 \t loss: -543.717 \t return: -1194.578 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  83 \t loss: -544.772 \t return: -1217.388 \t ep_len: 200.000\n",
      "obs_no (4200, 3)\n",
      "act_na (4200, 1)\n",
      "epoch:  84 \t loss: -537.878 \t return: -1219.689 \t ep_len: 200.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-cdb8b0e72317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mact_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mact_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-87-b2404b921622>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(env, epochs, buffer_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mbatch_rets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ckpts/_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-b2404b921622>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# act in the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-f2976ea6fd61>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#return tfpd.Normal(loc=input, scale=tf.exp(self.log_std))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_probability/python/layers/distribution_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enter_dunder_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     distribution, _ = super(DistributionLambda, self).__call__(\n\u001b[0;32m--> 245\u001b[0;31m         inputs, *args, **kwargs)\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enter_dunder_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_probability/python/layers/distribution_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     distribution, value = super(DistributionLambda, self).call(\n\u001b[0;32m--> 251\u001b[0;31m         inputs, *args, **kwargs)\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;31m# We always save the most recently built distribution for variable tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;31m# purposes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_check_variables\u001b[0;34m(self, created_variables, accessed_variables)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m     \u001b[0mtracked_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     untracked_new_vars = [v for v in created_variables\n\u001b[1;32m    859\u001b[0m                           if v.experimental_ref() not in tracked_weights]\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \"\"\"\n\u001b[0;32m--> 915\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_trainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_probability/python/layers/distribution_layer.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mfrom_keras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistributionLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mfrom_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_keras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrom_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_dedup_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   2390\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m     \u001b[0;34m\"\"\"Dedupe weights while maintaining order as much as possible.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2392\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentitySet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2393\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neu_env/.venv/lib/python3.6/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "obs_dim\n",
    "act_dim = env.action_space.shape[0]\n",
    "act_dim\n",
    "train(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(path, obs_dim, act_dim):\n",
    "    model = get_actor(obs_dim, act_dim)\n",
    "    model.load_weights(path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, env):\n",
    "    assert isinstance(env.observation_space, Box), \\\n",
    "        \"This is only for continuous observation space\"\n",
    "    assert isinstance(env.action_space, Box), \\\n",
    "        \"This is only for continuous action space\"\n",
    "\n",
    "    env.reset()\n",
    "    img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "\n",
    "    for _ in range(100):\n",
    "        img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        action = model(obs[None])[1][0]\n",
    "        env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-66232f13a401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobs_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mact_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(input_shape)\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                  shape=[int(input_shape[-1]),\n",
    "                                         self.num_outputs])\n",
    "\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)\n",
    "\n",
    "layer = MyDenseLayer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([5, 10])]\n"
     ]
    }
   ],
   "source": [
    "print([var.shape for var in layer.trainable_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
